---
navbar: false
sidebar: false
---

# 2000 条数据中查找 1000 条数据

要在第二次请求的 2000 条数据中查找第一次请求的 1000 条数据，可以使用以下几种常见的方法：

1. 暴力遍历法

   - 时间复杂度：`O(m * n)`，其中 `m` 是第二次请求的数据量（2000），`n` 是第一次请求的数据量（1000）。需要对第二次请求的每条数据都与第一次请求的所有数据进行比较。
   - 空间复杂度：`O(1)`，只需要额外的几个固定变量来进行比较操作，不需要额外的存储空间。
   - 如果数据量较大，5 秒内完成查找的可能性较低。特别是当第一次和第二次请求的数据量都很大时，时间复杂度为 O(m \* n)，可能会超出 5 秒。

**代码示例：**

```javascript
function bruteForceSearch(firstRequests, secondRequests) {
  const found = [];
  for (let i = 0; i < secondRequests.length; i++) {
    for (let j = 0; j < firstRequests.length; j++) {
      if (secondRequests[i] === firstRequests[j]) {
        found.push(secondRequests[i]);
        break;
      }
    }
  }
  return found;
}

// 示例用法
const firstRequests = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
const secondRequests = [
  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
];
console.log(bruteForceSearch(firstRequests, secondRequests));
```

2. 使用哈希表（Hash Table）

   - 首先将第一次请求的 1000 条数据存入哈希表，键为数据的值，值可以是任意固定值（比如 1）。
   - 然后遍历第二次请求的 2000 条数据，在哈希表中查找。
   - 时间复杂度：构建哈希表的时间复杂度为 `O(n)`，查找的时间复杂度为 `O(m)`，总体时间复杂度为 `O(n + m)`。在理想情况下，哈希表的查找时间复杂度接近 `O(1)`，所以总时间复杂度接近 `O(n + m)`。
   - 空间复杂度：`O(n)`，需要额外的空间来存储哈希表。
   - 在一般情况下，如果数据的哈希计算和查找操作效率较高，且硬件性能良好，有较大的可能性在 5 秒内完成查找。但如果数据的特征导致哈希冲突严重，可能会影响性能。

**代码示例：**

```javascript
function hashTableSearch(firstRequests, secondRequests) {
  const hash = {};
  for (let item of firstRequests) {
    hash[item] = 1;
  }
  const found = [];
  for (let item of secondRequests) {
    if (hash[item]) {
      found.push(item);
    }
  }
  return found;
}

// 示例用法
const firstRequests = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
const secondRequests = [
  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
];
console.log(hashTableSearch(firstRequests, secondRequests));
```

3. 先排序再二分查找
   - 对第一次请求的 1000 条数据和第二次请求的 2000 条数据分别进行排序。
   - 然后对于第一次请求的每条数据，在第二次请求已排序的数据中使用二分查找。
   - 时间复杂度：排序的时间复杂度为 `O(n log n + m log m)`，二分查找的时间复杂度为 `O(n log m)`，总体时间复杂度为 `O(n log n + m log m + n log m)`。
   - 空间复杂度：`O(1)`（如果使用原地排序算法），否则为 `O(n + m)`（用于存储排序后的数组）。
   - 排序本身需要一定的时间，如果数据量较大，排序可能就需要耗费不少时间。但对于已经排序好的数据进行二分查找是比较高效的。然而，如果整体数据量巨大，5 秒内完成的不确定性较大。

**代码示例：**

```javascript
function binarySearch(arr, target) {
  let left = 0;
  let right = arr.length - 1;

  while (left <= right) {
    const mid = Math.floor((left + right) / 2);

    if (arr[mid] === target) {
      return true;
    } else if (arr[mid] < target) {
      left = mid + 1;
    } else {
      right = mid - 1;
    }
  }

  return false;
}

function sortAndSearch(firstRequests, secondRequests) {
  firstRequests.sort((a, b) => a - b);
  secondRequests.sort((a, b) => a - b);

  const found = [];

  for (let item of firstRequests) {
    if (binarySearch(secondRequests, item)) {
      found.push(item);
    }
  }

  return found;
}

// 示例用法
const firstRequests = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
const secondRequests = [
  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
];
console.log(sortAndSearch(firstRequests, secondRequests));
```

在实际应用中，如果数据量不是特别大，使用哈希表可能是比较高效和方便的方法。但如果对空间使用有限制，或者数据本身有序，排序加二分查找可能是更好的选择。
